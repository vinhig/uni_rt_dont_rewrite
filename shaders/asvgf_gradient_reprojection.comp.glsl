#version 430 core

// Original implementation from Q2RTX
// https://github.com/NVIDIA/Q2RTX/blob/master/src/refresh/vkpt/shader/asvgf_gradient_reproject.comp
// Main changes:
// - reprojection slightly different (to be kept similar as the default
// reprojection in ta.comp.glsl, and the original svgf reprojection)
// - denoising isn't applied on separated noisy data, but rather on the whole
//   image generated by the embree backend (Q2RTX works on diffuse and specular,
//   while we work on both at the same time)
// - i still don't understand why every images are splitted into two parts in
//   q2rtx... here it's only one ofc (maybe for VR stuff idk)

#define GRAD_DWN (3)
#define GROUP_SIZE_GRAD 8
#define GROUP_SIZE_PIXELS (GROUP_SIZE_GRAD * GRAD_DWN)
#define BLUE_NOISE_RES (256)
#define NUM_BLUE_NOISE_TEX (128)
#define RNG_SEED_SHIFT_X 0u
#define RNG_SEED_SHIFT_Y 8u
#define RNG_SEED_SHIFT_ISODD 16u
#define RNG_SEED_SHIFT_FRAME 17u

#extension GL_ARB_enhanced_layouts : enable // to be allowed to use compile time
                                            // expression in some place (as in
                                            // layout definition)

layout(local_size_x = GROUP_SIZE_PIXELS, local_size_y = GROUP_SIZE_PIXELS,
       local_size_z = 1) in;

layout(binding = 0) uniform sampler2D t_curr_normal;
layout(binding = 1) uniform sampler2D t_prev_normal;

layout(binding = 2) uniform sampler2D t_curr_depth;
layout(binding = 3) uniform sampler2D t_prev_depth;

layout(binding = 4) uniform sampler2D t_prev_sample;

layout(binding = 5) uniform isampler2D t_curr_rng_seed;
layout(binding = 6) uniform isampler2D t_prev_rng_seed;

layout(binding = 7, r32ui) uniform restrict writeonly uimage2D t_out_rng_seed;
layout(binding = 8) uniform restrict writeonly image2D t_out_reprojected;

shared vec4 reprojected_lum[GROUP_SIZE_PIXELS][GROUP_SIZE_PIXELS];

layout(binding = 0, std140) uniform Reprojection {
  mat4 view_proj;
  mat4 inv_view_proj;
  mat4 prev_view_proj;
  mat4 proj;
  vec4 view_pos;
  vec2 target_dim;
  float alpha_illum;
  float alpha_moments;
  float phi_depth;
  float phi_normal;
  float depth_tolerance;
  float normal_tolerance;
  float min_accum_weight;
  uint frame_number;
}
uniforms;

float get_view_depth(float depth, mat4 proj) {
  // Returns linear depth in [near, far]
  return proj[3][2] / (proj[2][2] + (depth * 2.0 - 1.0));
}

float get_gradient(float l_curr, float l_prev) {
  float l_max = max(l_curr, l_prev);

  if (l_max == 0.0) {
    return 0.0;
  }

  float ret = abs(l_curr - l_prev) / l_max;
  ret *= ret; // make small changes less significant

  return ret;
}

uint generate_rng_seed(ivec2 ipos) {
  int frame_num = int(uniforms.frame_number);

  uint frame_offset = frame_num / NUM_BLUE_NOISE_TEX;

  uint rng_seed = 0;
  rng_seed |= (uint(ipos.x + frame_offset) % BLUE_NOISE_RES)
              << RNG_SEED_SHIFT_X;
  rng_seed |= (uint(ipos.y + (frame_offset << 4)) % BLUE_NOISE_RES)
              << RNG_SEED_SHIFT_Y;
  rng_seed |= uint(false) << RNG_SEED_SHIFT_ISODD;
  rng_seed |= uint(frame_num) << RNG_SEED_SHIFT_FRAME;

  return rng_seed;
}

vec3 unproject_uv(float depth, vec2 uv, mat4 inv_view_proj) {
  float z = depth * 2.0 - 1.0;
  vec4 ndc = vec4(uv * 2.0 - 1.0, z, 1.0);
  vec4 world = inv_view_proj * ndc;
  return world.xyz / world.w;
}

float get_view_depth(float depth) {
  // Returns linear depth in [near, far]
  return uniforms.proj[3][2] / (uniforms.proj[2][2] + (depth * 2.0 - 1.0));
}

bool in_bounds(vec2 coord) {
  return all(lessThan(coord, uniforms.target_dim)) &&
         all(greaterThanEqual(coord, ivec2(0)));
}

float luminance(vec3 color) { return dot(color, vec3(0.2126, 0.7152, 0.0722)); }

float depth_weight(float prev_depth, float curr_depth, vec3 curr_normal,
                   vec3 view_dir, mat4 proj, float phi) {
  float linear_depth_prv = get_view_depth(prev_depth, proj);

  float linear_depth = get_view_depth(curr_depth, proj);

  float angle_factor = max(0.25, -dot(curr_normal, view_dir));

  float diff = abs(linear_depth_prv - linear_depth);
  return exp(-diff * angle_factor / phi);
}

float normal_weight(vec3 prev_normal, vec3 curr_normal, float phi) {
  // float d = max(0, dot(curr_normal, prev_normal));
  // return d * d;
  vec3 dd = prev_normal - curr_normal;
  float d = dot(dd, dd);
  return exp(-d / phi);
}

void reproject_pixel(ivec2 curr_coord) {
  vec2 uv = (vec2(curr_coord) + 0.5) / uniforms.target_dim;

  float curr_depth = texelFetch(t_curr_depth, curr_coord, 0).x;

  // Reproject current sample
  // vec4 curr_pos = vec4(texelFetch(t_curr_position, curr_coord, 0).rgb, 1.0);
  vec4 curr_pos =
      vec4(unproject_uv(curr_depth, uv, uniforms.inv_view_proj), 1.0);

  vec4 yeah = uniforms.prev_view_proj * curr_pos;
  yeah.xyz /= yeah.w;
  yeah.xy = yeah.xy * 0.5 + 0.5;

  ivec2 prev_coord = ivec2(yeah.xy * uniforms.target_dim - 0.5);

  curr_depth =
      get_view_depth(texelFetch(t_curr_depth, curr_coord, 0).x, uniforms.proj);
  float prev_depth =
      get_view_depth(texelFetch(t_prev_depth, prev_coord, 0).x, uniforms.proj);

  vec3 curr_norm = texelFetch(t_curr_normal, curr_coord, 0).xyz;
  vec3 prev_norm = texelFetch(t_prev_normal, prev_coord, 0).xyz;

  float dist_depth = abs(curr_depth - prev_depth);
  float dist_normal = dot(prev_norm - curr_norm, prev_norm - curr_norm);

  if (dist_normal < 1.0 && dist_depth < 0.5) {
    vec4 stuff = vec4(0);
    stuff.xy = vec2(prev_coord);
    stuff.z = luminance(texelFetch(t_prev_sample, prev_coord, 0).rgb);
    reprojected_lum[gl_LocalInvocationID.y][gl_LocalInvocationID.x] = stuff;
  } else {
    reprojected_lum[gl_LocalInvocationID.y][gl_LocalInvocationID.x] =
        vec4(-1.0);
  }
}

void main() {
  // Simple reprojection mechanism, don't need anything fancy
  // as the output will be blurred gradient

  // ipos is the position inside the 1280x720 texture yes yes
  ivec2 curr_coord = ivec2(gl_GlobalInvocationID);

  imageStore(t_out_reprojected, curr_coord / 3, vec4(0.0));
  imageStore(t_out_rng_seed, curr_coord, uvec4(generate_rng_seed(curr_coord)));

  reproject_pixel(curr_coord);

  barrier();

  ivec2 local_pos;
  local_pos.x = int(gl_LocalInvocationIndex) % GROUP_SIZE_GRAD;
  local_pos.y = int(gl_LocalInvocationIndex) / GROUP_SIZE_GRAD;

  if (local_pos.y >= GROUP_SIZE_GRAD) {
    return;
  }

  ivec2 pos_grad = ivec2(gl_WorkGroupID) * GROUP_SIZE_GRAD + local_pos;
  curr_coord = pos_grad * GRAD_DWN;

  bool found = false;
  ivec2 found_offset = ivec2(0);
  ivec2 found_pos_prev = ivec2(0);
  float found_prev_lum = -1.0;

  // TODO: choose the sample closest to the mean of the 9 samples
  for (int offy = 0; offy < GRAD_DWN; offy++) {
    for (int offx = 0; offx < GRAD_DWN; offx++) {
      ivec2 p = local_pos * GRAD_DWN + ivec2(offx, offy);

      vec4 prev_lum = reprojected_lum[p.y][p.x];

      if (prev_lum.z > found_prev_lum) {
        found_prev_lum = prev_lum.z;
        found_offset = ivec2(offx, offy);
        found_pos_prev = ivec2(prev_lum.xy);
        found = true;
      }
    }
  }

  if (!found) {
    imageStore(t_out_reprojected, pos_grad, vec4(0.0));
    return;
  }

  imageStore(t_out_reprojected, pos_grad, vec4(found_prev_lum));
  imageStore(t_out_rng_seed, curr_coord + found_offset,
             uvec4(generate_rng_seed(curr_coord)));
}